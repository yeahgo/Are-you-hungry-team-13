{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Restaurant Recommendation System based on Yelp Information ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Goal**: Create an NYC restaurant information database and use the database to recommend users restaurants which match with their preferences.\n",
    "\n",
    "Users can input features that indicate their preferences and our machine can output top 5 restaurants from as our recommendation for the user.\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "1. We use \"Yelp Restaurant Info Scraper.ipynb\" to get search urls and scrape information for restaurants in different categories in all locations in NYC. We ran the script on our local machines.\n",
    "\n",
    "2. After getting the csv for each type of restaurant, we use \"Dataframe Cleaner.ipynb\" to clean and merge all the csv files as a final dataframe. We use this final dataframe as our database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from threading import Thread\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import time\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opener = urllib.request.build_opener()\n",
    "# IE 9 proved to be the most successful\n",
    "opener.addheaders = [('User-agent', 'IE 9/Windows: Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will do the scraping job from yelp\n",
    "def scrape(ur):\n",
    "\n",
    "    with urllib.request.urlopen(ur) as url:\n",
    "        html = url.read()\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    retaurant_name = soup.find('h1')\n",
    "    \n",
    "    # create a dictionary business info for storing key business features \n",
    "    business_info = {}\n",
    "    business_info['restaurant_name']= str(retaurant_name.text.strip().rstrip())\n",
    "    \n",
    "    if soup.find('span',itemprop=\"streetAddress\") != None:\n",
    "        retaurant_address = soup.find('span',itemprop=\"streetAddress\")\n",
    "        business_info['retaurant_address'] = str(retaurant_address.text.strip().rstrip())\n",
    "    \n",
    "    if soup.find('span',itemprop=\"postalCode\") != None:\n",
    "        restaurant_zipcode = soup.find('span',itemprop=\"postalCode\")\n",
    "        business_info['restaurant_zipcode'] = str(restaurant_zipcode.text.strip().rstrip())\n",
    "    \n",
    "    if soup.find('span',itemprop=\"reviewCount\") != None:\n",
    "        restaurant_reviewcount = soup.find('span',itemprop=\"reviewCount\")\n",
    "        business_info['restaurant_reviewcount'] = str(restaurant_reviewcount.text.strip().rstrip())\n",
    "   \n",
    "    if soup.find(itemprop=\"ratingValue\") != None:\n",
    "        business_info['restaurant_rating'] = soup.find(itemprop=\"ratingValue\").get(\"content\")\n",
    "\n",
    "    if soup.find('span', {'class': 'neighborhood-str-list'}) != None:\n",
    "        neighborhood = soup.find('span', {'class': 'neighborhood-str-list'})\n",
    "        business_info['restaurant_neighobrhood'] = str(neighborhood.text.strip().rstrip())\n",
    "   \n",
    "    if soup.find('dd',{'class':\"nowrap health-score-description\"}) != None:\n",
    "        hygiene_score = soup.find('dd',{'class':\"nowrap health-score-description\"})\n",
    "        business_info['Hygiene_score'] = str(hygiene_score.text.strip().rstrip())\n",
    "        \n",
    "    if soup.find('dd', {'class':\"nowrap price-description\"}) != None:\n",
    "        price_range = soup.find('dd', {'class':\"nowrap price-description\"})\n",
    "        business_info['price_range'] = str(price_range.text.strip().rstrip())\n",
    "   \n",
    "    if soup.find('div',{'class':'short-def-list'}) != None:\n",
    "        for i in soup.find('div',{'class':'short-def-list'}).findAll('dl'):\n",
    "            key = i.find('dt').text.strip().rstrip()\n",
    "            value = i.find('dd').text.strip().rstrip()\n",
    "            business_info[str(key)]=str(value)\n",
    "    \n",
    "    if soup.find(property=\"place:location:latitude\") != None:\n",
    "        business_info['latitude'] = soup.find(property=\"place:location:latitude\").get(\"content\")\n",
    "\n",
    "    if soup.find(property=\"place:location:longitude\") != None:\n",
    "        business_info['longitude'] = soup.find(property=\"place:location:longitude\").get(\"content\")  \n",
    "    \n",
    "    business_info['Category']= ''\n",
    "    if soup.find('span',{'class':'category-str-list'}) != None:\n",
    "        for i in soup.find('span',{'class':'category-str-list'}).findAll('a'):\n",
    "            business_info['Category'] += (str(i.text.strip().rstrip())+'; ')\n",
    "                \n",
    "    return business_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for the scrape function\n",
    "d = scrape('https://www.yelp.com/biz/blue-ribbon-sushi-new-york?osq=blue+ribbon')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of yelp urls to scrape\n",
    "def get_urls_from_search(term, location, num):\n",
    "    \n",
    "    term = term.replace(' ','+')\n",
    "    location = location.replace(' ','+')\n",
    "    query = 'https://www.yelp.com/search?find_desc='+term+'&find_loc='+location+'&start='+str(num*10)\n",
    "    with urllib.request.urlopen(query) as url:\n",
    "        contents = url.read()\n",
    "    #contents = urllib.urlopen(query).read()\n",
    "    soup = BeautifulSoup(contents, \"html.parser\")\n",
    "    #print(soup)\n",
    "    business_url = []\n",
    "    for result in soup.findAll('a',{'class':'biz-name js-analytics-click'}):\n",
    "        business_url.append(\"http://www.yelp.com\" + result['href'])\n",
    "    return business_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all locations\n",
    "# 'Alphabet_City','Battery_Park','Chelsea','Chinatown','Civic_Center','East_Harlem','East_Village','Financial_District','Flatiron','Gramercy','Greenwich_Village','Harlem','Hell\\'s_Kitchen','Inwood','Kips_Bay','Koreatown','Little_Italy','Lower_East_Side','Manhattan_Valley','Marble_Hill','Meatpacking_District','Midtown_East','Midtown_West','Morningside_Heights','Murray_Hill','NoHo','Nolita','Roosevelt_Island','SoHo','South_Street_Seaport','South_Village','Stuyvesant_Town','Theater_District','TriBeCa','Two_Bridges','Union_Square','Upper_East_Side','Upper_West_Side','Washington_Heights','West_Village', 'Yorkville'\n",
    "\n",
    "# Yorkville entirely encompassed by Upper East Side\n",
    "# Theater District entirely encompassed by Midtown West\n",
    "\n",
    "searchLocations = ['Alphabet_City','Battery_Park','Chelsea','Chinatown','Civic_Center','East_Harlem','East_Village','Financial_District','Flatiron','Gramercy','Greenwich_Village','Harlem','Hell\\'s_Kitchen','Inwood','Kips_Bay','Koreatown','Little_Italy','Lower_East_Side','Manhattan_Valley','Marble_Hill','Meatpacking_District','Midtown_East','Midtown_West','Morningside_Heights','Murray_Hill','NoHo','Nolita','Roosevelt_Island','SoHo','South_Street_Seaport','South_Village','Stuyvesant_Town','TriBeCa','Two_Bridges','Union_Square','Upper_East_Side','Upper_West_Side','Washington_Heights','West_Village']\n",
    "\n",
    "#test\n",
    "#searchLocations = ['East_Village', 'Upper_West_Side', 'Chelsea'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = 5\n",
    "urls_set = []\n",
    "for i, loc in enumerate(searchLocations):\n",
    "    # now run for loop with fix location and food type and append urls \n",
    "    # page ranking is based on relevance ranked by yelp\n",
    "    for num in range(0,max_num):\n",
    "        urls = get_urls_from_search(\"Japanese restaurants\",loc, num)\n",
    "        urls = urls[1:] # 0th link is irrelavant\n",
    "        # len(urls)=0 if the starting page number exceed the maximum possible\n",
    "        if (len(urls) ==0):\n",
    "            break\n",
    "        else:\n",
    "            for i in range(0,len(urls)-1):\n",
    "                urls_set.append(urls[i])\n",
    "                \n",
    "    # Delays to help reduce queries and reduce the possibility of IP Ban            \n",
    "    time.sleep(5)\n",
    "    #convert the urls from list to csv file for each location\n",
    "    #pd_urls_set = pd.DataFrame(urls_set)\n",
    "    #pd_urls_set.to_csv(\"urls_set_{0}.csv\".format(loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(urls_set))\n",
    "urls_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info = {} # create a dictionary for srestaurant info\n",
    "for u in urls_set:\n",
    "    url_dict=scrape(u)\n",
    "    for key,value in url_dict.items():\n",
    "        info.setdefault(key,[]).append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['restaurant_name', 'retaurant_address', 'restaurant_zipcode', 'restaurant_reviewcount', 'restaurant_rating', 'Hygiene_score', 'price_range', 'Takes Reservations', 'Delivery', 'Take-out', 'Accepts Credit Cards', 'Accepts Apple Pay', 'Accepts Google Pay', 'Accepts Bitcoin', 'Good For', 'Parking', 'Bike Parking', 'Wheelchair Accessible', 'Good for Kids', 'Good for Groups', 'Attire', 'Ambience', 'Noise Level', 'Alcohol', 'Happy Hour', 'Outdoor Seating', 'Wi-Fi', 'Has TV', 'Dogs Allowed', 'Waiter Service', 'Caters', 'Gender Neutral Restrooms', 'Has Dairy-free Options', 'Liked by Vegetarians', 'Liked by Vegans', 'Good For Dancing', 'Best Nights', 'Good for Working', 'Has Pool Table', 'Open to All', 'Coat Check', 'Has Soy-free Options', 'Has Gluten-free Options', 'Smoking', 'Has Kosher Options', 'Offers Military Discount']\n",
    "info={}\n",
    "for u in urls_set:\n",
    "    url_dict=scrape(u)\n",
    "    for i in header:\n",
    "        if i in url_dict.keys():\n",
    "            info.setdefault(i,[]).append(url_dict[i])\n",
    "        else:\n",
    "            info.setdefault(i,[]).append('NA')\n",
    "    # Delays to help reduce queries and reduce the possibility of IP Ban\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_sample=pd.DataFrame(info)\n",
    "#final_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_sample.to_csv('sample japnese.csv') # save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = 5\n",
    "urls_set = []\n",
    "for i, loc in enumerate(searchLocations):\n",
    "    # now run for loop with fix location and food type and append urls \n",
    "    # page ranking is based on relevance ranked by yelp\n",
    "    for num in range(0,max_num):\n",
    "        urls = get_urls_from_search(\"Chinese restaurants\",loc, num)\n",
    "        urls = urls[1:] # 0th link is irrelavant\n",
    "        # len(urls)=0 if the starting page number exceed the maximum possible\n",
    "        if (len(urls) ==0):\n",
    "            break\n",
    "        else:\n",
    "            for i in range(0,len(urls)-1):\n",
    "                urls_set.append(urls[i])\n",
    "                \n",
    "    time.sleep(5)\n",
    "    #convert the urls from list to csv file for each location\n",
    "    #pd_urls_set = pd.DataFrame(urls_set)\n",
    "    #pd_urls_set.to_csv(\"urls_set_{0}.csv\".format(loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['restaurant_name', 'retaurant_address', 'restaurant_zipcode', 'restaurant_reviewcount', 'restaurant_rating', 'restaurant_neighobrhood', 'Hygiene_score', 'price_range', 'Liked by Vegetarians', 'Takes Reservations', 'Delivery', 'Take-out', 'Accepts Credit Cards', 'Accepts Bitcoin', 'Parking', 'Bike Parking', 'Wheelchair Accessible', 'Good for Kids', 'Good for Groups', 'Attire', 'Noise Level', 'Alcohol', 'Happy Hour', 'Outdoor Seating', 'Wi-Fi', 'Has TV', 'Dogs Allowed', 'Waiter Service', 'Caters', 'Category', 'Has Soy-free Options', 'Has Dairy-free Options', 'Liked by Vegans', 'Has Gluten-free Options', 'Good For', 'Ambience', 'Gender Neutral Restrooms']\n",
    "info={}\n",
    "for u in urls_set[:30]:\n",
    "    url_dict=scrape(u)\n",
    "    for i in header:\n",
    "        if i in url_dict.keys():\n",
    "            info.setdefault(i,[]).append(url_dict[i])\n",
    "        else:\n",
    "            info.setdefault(i,[]).append('NA')\n",
    "     # Delays to help reduce queries and reduce the possibility of IP Ban\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(info)\n",
    "df.to_csv('sample chinese.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Please enter a restaurant name below, if you have no idea about it, just click return')\n",
    "name=input(\"restaurant name: \")\n",
    "\n",
    "if name=='':\n",
    "    #return the original csv\n",
    "else:\n",
    "    #return the selceted csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Please enter a restaurant style below, if you have no idea about it, just click return')\n",
    "style = input(\"style: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Are you going to eat Lunch, Dinner or Breakfast?, please input Lunch or Dinner, if you have no idea about it, just click return')\n",
    "mealkind = input(\"Lunch, Dinner or Breakfast :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Want to find a place to drink alcohol? Please enter: Full Bar, Beer&Wine Only or No below')\n",
    "alcohol = input(\"alcohol:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"enter your current location: \")\n",
    "zipcode = input(\"location:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to output the restaurants with highest Yelp ratings and good hygiene for the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hehe = pd.read_csv('/Users/haodi_liu/Desktop/final_df.csv', encoding='latin1')\n",
    "\n",
    "\n",
    "hehe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_for_name(df):\n",
    "    \n",
    "    nl = []\n",
    "    while True:\n",
    "        print('Please enter a restaurant name below, if you have no idea about it, just click return')\n",
    "        name=input(\"Restaurant name: \")\n",
    "        \n",
    "        if name == '':\n",
    "            return df\n",
    "        \n",
    "        for item in df['restaurant_name'].tolist():\n",
    "            if re.search(name.lower(), item.lower()):\n",
    "                nl.append(item)\n",
    "        \n",
    "        if len(nl) == 0:\n",
    "            print('Please enter a valid name.')\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return df.loc[df['restaurant_name'].isin(nl)]\n",
    "\n",
    "def ask_for_neighbor(df):\n",
    "    \n",
    "    nl = []\n",
    "    while True:\n",
    "        print('Please enter a restaurant neighborhood below, if you have no idea about it, just click return')\n",
    "        neighbor = input(\"Restaurant neighborhood: \")\n",
    "        \n",
    "        if neighbor == '':\n",
    "            return df\n",
    "        elif neighbor not in df['restaurant_neighobrhood'].tolist():\n",
    "            print('Please enter a valid neighbor name.')\n",
    "            continue\n",
    "        else:\n",
    "            nl.append(neighbor)\n",
    "            if_con = input(\"Do you want to keep adding? Enter 1 if you do. \")\n",
    "            if if_con != '1':\n",
    "                break\n",
    "    print(nl)\n",
    "    return df.loc[df['restaurant_neighobrhood'].isin(nl)]\n",
    "\n",
    "def ask_for_rating(df):\n",
    "    \n",
    "    while True:\n",
    "        print(\"Please enter a range of your expected rating below, if you have no idea about it, just click return\")\n",
    "        lb = input(\"Please enter a lower bound of rating range you are looking for :\")\n",
    "        ub = input(\"Please enter an upper bound of rating range you are looking for :\")\n",
    "        \n",
    "        if lb == '' and ub == '':\n",
    "            return df\n",
    "        \n",
    "        if lb == '':\n",
    "            lb = '0'\n",
    "        \n",
    "        if ub == '':\n",
    "            ub = '5'\n",
    "            \n",
    "        if float(lb) > float(ub):\n",
    "            print('Lower bound has to be smaller than the upper bound.')\n",
    "            continue\n",
    "        \n",
    "        if float(lb) < 0 or float(ub) > 5:\n",
    "            print('The range of rating has to be between 0 and 5.')\n",
    "            continue\n",
    "            \n",
    "        return df.loc[(df['restaurant_rating'] >= float(lb)) & (df['restaurant_rating'] <= float(ub))]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_for_name(pd.read_csv('/Users/haodi_liu/Desktop/final_df.csv', encoding='latin1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df = pd.read_csv('final_df.csv', encoding='latin1')\n",
    "#original_name = global_df['restaurant_name'].tolist()\n",
    "#global_df = ask_for_name(global_df)\n",
    "done = False\n",
    "\n",
    "while done == False:\n",
    "    \n",
    "    global_df = ask_for_name(global_df)\n",
    "    length = len(global_df['restaurant_name'].tolist())\n",
    "    print(f\"There are {length} restaurants filtered out so far\")\n",
    "    con = input('Do you want to keep searching? Enter 0 if you are done with searching')\n",
    "    if con == '0':\n",
    "        break\n",
    "    \n",
    "    global_df = ask_for_neighbor(global_df)\n",
    "    length = len(global_df['restaurant_name'].tolist())\n",
    "    print(f\"There are {length} restaurants filtered out so far\")\n",
    "    con1 = input('Do you want to keep searching? Enter 0 if you are done with searching')\n",
    "    if con1 == '0':\n",
    "        break\n",
    "    \n",
    "    global_df = ask_for_rating(global_df)\n",
    "    length = len(global_df['restaurant_name'].tolist())\n",
    "    print(f\"There are {length} restaurants filtered out so far\")\n",
    "    con2 = input('Do you want to keep searching? Enter 0 if you are done with searching')\n",
    "    if con2 == '0':\n",
    "        break\n",
    "        \n",
    "    done = True\n",
    "    \n",
    "\n",
    "global_df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
