{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Restaurant Recommendation System based on Yelp Information ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Goal**: Create an NYC restaurant information database and use the database to recommend users restaurants which match with their preferences.\n",
    "\n",
    "Users can input features that indicate their preferences and our machine can output top 5 restaurants from as our recommendation for the user.\n",
    "\n",
    "**Steps**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from threading import Thread\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import time\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opener = urllib.request.build_opener()\n",
    "# IE 9 proved to be the most successful\n",
    "opener.addheaders = [('User-agent', 'IE 9/Windows: Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will do the scraping job from yelp\n",
    "def scrape(ur):\n",
    "\n",
    "    with urllib.request.urlopen(ur) as url:\n",
    "        html = url.read()\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    retaurant_name = soup.find('h1')\n",
    "    \n",
    "    # create a dictionary business info for storing key business features \n",
    "    business_info = {}\n",
    "    business_info['restaurant_name']= str(retaurant_name.text.strip().rstrip())\n",
    "    \n",
    "    if soup.find('span',itemprop=\"streetAddress\") != None:\n",
    "        retaurant_address = soup.find('span',itemprop=\"streetAddress\")\n",
    "        business_info['retaurant_address'] = str(retaurant_address.text.strip().rstrip())\n",
    "    \n",
    "    if soup.find('span',itemprop=\"postalCode\") != None:\n",
    "        restaurant_zipcode = soup.find('span',itemprop=\"postalCode\")\n",
    "        business_info['restaurant_zipcode'] = str(restaurant_zipcode.text.strip().rstrip())\n",
    "    \n",
    "    if soup.find('span',itemprop=\"reviewCount\") != None:\n",
    "        restaurant_reviewcount = soup.find('span',itemprop=\"reviewCount\")\n",
    "        business_info['restaurant_reviewcount'] = str(restaurant_reviewcount.text.strip().rstrip())\n",
    "   \n",
    "    if soup.find(itemprop=\"ratingValue\") != None:\n",
    "        business_info['restaurant_rating'] = soup.find(itemprop=\"ratingValue\").get(\"content\")\n",
    "\n",
    "    if soup.find('span', {'class': 'neighborhood-str-list'}) != None:\n",
    "        neighborhood = soup.find('span', {'class': 'neighborhood-str-list'})\n",
    "        business_info['restaurant_neighobrhood'] = str(neighborhood.text.strip().rstrip())\n",
    "   \n",
    "    if soup.find('dd',{'class':\"nowrap health-score-description\"}) != None:\n",
    "        hygiene_score = soup.find('dd',{'class':\"nowrap health-score-description\"})\n",
    "        business_info['Hygiene_score'] = str(hygiene_score.text.strip().rstrip())\n",
    "        \n",
    "    if soup.find('dd', {'class':\"nowrap price-description\"}) != None:\n",
    "        price_range = soup.find('dd', {'class':\"nowrap price-description\"})\n",
    "        business_info['price_range'] = str(price_range.text.strip().rstrip())\n",
    "   \n",
    "    if soup.find('div',{'class':'short-def-list'}) != None:\n",
    "        for i in soup.find('div',{'class':'short-def-list'}).findAll('dl'):\n",
    "            key = i.find('dt').text.strip().rstrip()\n",
    "            value = i.find('dd').text.strip().rstrip()\n",
    "            business_info[str(key)]=str(value)\n",
    "    \n",
    "    if soup.find(property=\"place:location:latitude\") != None:\n",
    "        business_info['latitude'] = soup.find(property=\"place:location:latitude\").get(\"content\")\n",
    "\n",
    "    if soup.find(property=\"place:location:longitude\") != None:\n",
    "        business_info['longitude'] = soup.find(property=\"place:location:longitude\").get(\"content\")  \n",
    "    \n",
    "    business_info['Category']= ''\n",
    "    if soup.find('span',{'class':'category-str-list'}) != None:\n",
    "        for i in soup.find('span',{'class':'category-str-list'}).findAll('a'):\n",
    "            business_info['Category'] += (str(i.text.strip().rstrip())+'; ')\n",
    "                \n",
    "    return business_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for the scrape function\n",
    "d = scrape('https://www.yelp.com/biz/blue-ribbon-sushi-new-york?osq=blue+ribbon')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of yelp urls to scrape\n",
    "def get_urls_from_search(term, location, num):\n",
    "    \n",
    "    term = term.replace(' ','+')\n",
    "    location = location.replace(' ','+')\n",
    "    query = 'https://www.yelp.com/search?find_desc='+term+'&find_loc='+location+'&start='+str(num*10)\n",
    "    with urllib.request.urlopen(query) as url:\n",
    "        contents = url.read()\n",
    "    #contents = urllib.urlopen(query).read()\n",
    "    soup = BeautifulSoup(contents, \"html.parser\")\n",
    "    #print(soup)\n",
    "    business_url = []\n",
    "    for result in soup.findAll('a',{'class':'biz-name js-analytics-click'}):\n",
    "        business_url.append(\"http://www.yelp.com\" + result['href'])\n",
    "    return business_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all locations\n",
    "# 'Alphabet_City','Battery_Park','Chelsea','Chinatown','Civic_Center','East_Harlem','East_Village','Financial_District','Flatiron','Gramercy','Greenwich_Village','Harlem','Hell\\'s_Kitchen','Inwood','Kips_Bay','Koreatown','Little_Italy','Lower_East_Side','Manhattan_Valley','Marble_Hill','Meatpacking_District','Midtown_East','Midtown_West','Morningside_Heights','Murray_Hill','NoHo','Nolita','Roosevelt_Island','SoHo','South_Street_Seaport','South_Village','Stuyvesant_Town','Theater_District','TriBeCa','Two_Bridges','Union_Square','Upper_East_Side','Upper_West_Side','Washington_Heights','West_Village', 'Yorkville'\n",
    "\n",
    "# Yorkville entirely encompassed by Upper East Side\n",
    "# Theater District entirely encompassed by Midtown West\n",
    "\n",
    "searchLocations = ['Alphabet_City','Battery_Park','Chelsea','Chinatown','Civic_Center','East_Harlem','East_Village','Financial_District','Flatiron','Gramercy','Greenwich_Village','Harlem','Hell\\'s_Kitchen','Inwood','Kips_Bay','Koreatown','Little_Italy','Lower_East_Side','Manhattan_Valley','Marble_Hill','Meatpacking_District','Midtown_East','Midtown_West','Morningside_Heights','Murray_Hill','NoHo','Nolita','Roosevelt_Island','SoHo','South_Street_Seaport','South_Village','Stuyvesant_Town','TriBeCa','Two_Bridges','Union_Square','Upper_East_Side','Upper_West_Side','Washington_Heights','West_Village']\n",
    "\n",
    "#test\n",
    "#searchLocations = ['East_Village', 'Upper_West_Side', 'Chelsea'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = 5\n",
    "urls_set = []\n",
    "for i, loc in enumerate(searchLocations):\n",
    "    # now run for loop with fix location and food type and append urls \n",
    "    # page ranking is based on relevance ranked by yelp\n",
    "    for num in range(0,max_num):\n",
    "        urls = get_urls_from_search(\"Japanese restaurants\",loc, num)\n",
    "        urls = urls[1:] # 0th link is irrelavant\n",
    "        # len(urls)=0 if the starting page number exceed the maximum possible\n",
    "        if (len(urls) ==0):\n",
    "            break\n",
    "        else:\n",
    "            for i in range(0,len(urls)-1):\n",
    "                urls_set.append(urls[i])\n",
    "                \n",
    "    # Delays to help reduce queries and reduce the possibility of IP Ban            \n",
    "    time.sleep(5)\n",
    "    #convert the urls from list to csv file for each location\n",
    "    #pd_urls_set = pd.DataFrame(urls_set)\n",
    "    #pd_urls_set.to_csv(\"urls_set_{0}.csv\".format(loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(urls_set))\n",
    "urls_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info = {} # create a dictionary for srestaurant info\n",
    "for u in urls_set:\n",
    "    url_dict=scrape(u)\n",
    "    for key,value in url_dict.items():\n",
    "        info.setdefault(key,[]).append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['restaurant_name', 'retaurant_address', 'restaurant_zipcode', 'restaurant_reviewcount', 'restaurant_rating', 'Hygiene_score', 'price_range', 'Takes Reservations', 'Delivery', 'Take-out', 'Accepts Credit Cards', 'Accepts Apple Pay', 'Accepts Google Pay', 'Accepts Bitcoin', 'Good For', 'Parking', 'Bike Parking', 'Wheelchair Accessible', 'Good for Kids', 'Good for Groups', 'Attire', 'Ambience', 'Noise Level', 'Alcohol', 'Happy Hour', 'Outdoor Seating', 'Wi-Fi', 'Has TV', 'Dogs Allowed', 'Waiter Service', 'Caters', 'Gender Neutral Restrooms', 'Has Dairy-free Options', 'Liked by Vegetarians', 'Liked by Vegans', 'Good For Dancing', 'Best Nights', 'Good for Working', 'Has Pool Table', 'Open to All', 'Coat Check', 'Has Soy-free Options', 'Has Gluten-free Options', 'Smoking', 'Has Kosher Options', 'Offers Military Discount']\n",
    "info={}\n",
    "for u in urls_set:\n",
    "    url_dict=scrape(u)\n",
    "    for i in header:\n",
    "        if i in url_dict.keys():\n",
    "            info.setdefault(i,[]).append(url_dict[i])\n",
    "        else:\n",
    "            info.setdefault(i,[]).append('NA')\n",
    "    # Delays to help reduce queries and reduce the possibility of IP Ban\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_sample=pd.DataFrame(info)\n",
    "#final_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_sample.to_csv('sample japnese.csv') # save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = 5\n",
    "urls_set = []\n",
    "for i, loc in enumerate(searchLocations):\n",
    "    # now run for loop with fix location and food type and append urls \n",
    "    # page ranking is based on relevance ranked by yelp\n",
    "    for num in range(0,max_num):\n",
    "        urls = get_urls_from_search(\"Chinese restaurants\",loc, num)\n",
    "        urls = urls[1:] # 0th link is irrelavant\n",
    "        # len(urls)=0 if the starting page number exceed the maximum possible\n",
    "        if (len(urls) ==0):\n",
    "            break\n",
    "        else:\n",
    "            for i in range(0,len(urls)-1):\n",
    "                urls_set.append(urls[i])\n",
    "                \n",
    "    time.sleep(5)\n",
    "    #convert the urls from list to csv file for each location\n",
    "    #pd_urls_set = pd.DataFrame(urls_set)\n",
    "    #pd_urls_set.to_csv(\"urls_set_{0}.csv\".format(loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['restaurant_name', 'retaurant_address', 'restaurant_zipcode', 'restaurant_reviewcount', 'restaurant_rating', 'restaurant_neighobrhood', 'Hygiene_score', 'price_range', 'Liked by Vegetarians', 'Takes Reservations', 'Delivery', 'Take-out', 'Accepts Credit Cards', 'Accepts Bitcoin', 'Parking', 'Bike Parking', 'Wheelchair Accessible', 'Good for Kids', 'Good for Groups', 'Attire', 'Noise Level', 'Alcohol', 'Happy Hour', 'Outdoor Seating', 'Wi-Fi', 'Has TV', 'Dogs Allowed', 'Waiter Service', 'Caters', 'Category', 'Has Soy-free Options', 'Has Dairy-free Options', 'Liked by Vegans', 'Has Gluten-free Options', 'Good For', 'Ambience', 'Gender Neutral Restrooms']\n",
    "info={}\n",
    "for u in urls_set[:30]:\n",
    "    url_dict=scrape(u)\n",
    "    for i in header:\n",
    "        if i in url_dict.keys():\n",
    "            info.setdefault(i,[]).append(url_dict[i])\n",
    "        else:\n",
    "            info.setdefault(i,[]).append('NA')\n",
    "     # Delays to help reduce queries and reduce the possibility of IP Ban\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(info)\n",
    "df.to_csv('sample chinese.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Please enter a restaurant name below, if you have no idea about it, just click return')\n",
    "name=input(\"restaurant name: \")\n",
    "\n",
    "if name=='':\n",
    "    #return the original csv\n",
    "else:\n",
    "    #return the selceted csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Please enter a restaurant style below, if you have no idea about it, just click return')\n",
    "style = input(\"style: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Are you going to eat Lunch, Dinner or Breakfast?, please input Lunch or Dinner, if you have no idea about it, just click return')\n",
    "mealkind = input(\"Lunch, Dinner or Breakfast :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Want to find a place to drink alcohol? Please enter: Full Bar, Beer&Wine Only or No below')\n",
    "alcohol = input(\"alcohol:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"enter your current location: \")\n",
    "zipcode = input(\"location:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to output the restaurants with highest Yelp ratings and good hygiene for the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/haodi_liu/Downloads/Sample Japanese Restaurant.csv')\n",
    "'Hirohisa' in df['restaurant_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a restaurant name below, if you have no idea about it, just click return\n",
      "restaurant name: Hirohisa\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Accepts Apple Pay</th>\n",
       "      <th>Accepts Bitcoin</th>\n",
       "      <th>Accepts Credit Cards</th>\n",
       "      <th>Accepts Google Pay</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Ambience</th>\n",
       "      <th>Attire</th>\n",
       "      <th>Bike Parking</th>\n",
       "      <th>Caters</th>\n",
       "      <th>...</th>\n",
       "      <th>Parking</th>\n",
       "      <th>Take-out</th>\n",
       "      <th>Takes Reservations</th>\n",
       "      <th>Waiter Service</th>\n",
       "      <th>Wheelchair Accessible</th>\n",
       "      <th>Wi-Fi</th>\n",
       "      <th>restaurant_name</th>\n",
       "      <th>restaurant_reviewcount</th>\n",
       "      <th>restaurant_zipcode</th>\n",
       "      <th>retaurant_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beer &amp; Wine Only</td>\n",
       "      <td>Classy, Upscale</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Street</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Hirohisa</td>\n",
       "      <td>131</td>\n",
       "      <td>10012</td>\n",
       "      <td>73 Thompson St</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 Accepts Apple Pay Accepts Bitcoin Accepts Credit Cards  \\\n",
       "22          22                No             NaN                  Yes   \n",
       "\n",
       "   Accepts Google Pay           Alcohol         Ambience  Attire Bike Parking  \\\n",
       "22                NaN  Beer & Wine Only  Classy, Upscale  Casual          Yes   \n",
       "\n",
       "   Caters        ...        Parking Take-out Takes Reservations  \\\n",
       "22    Yes        ...         Street       No                Yes   \n",
       "\n",
       "   Waiter Service Wheelchair Accessible Wi-Fi restaurant_name  \\\n",
       "22            NaN                   NaN    No        Hirohisa   \n",
       "\n",
       "   restaurant_reviewcount restaurant_zipcode retaurant_address  \n",
       "22                    131              10012    73 Thompson St  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_for_name(ab_path):\n",
    "    print('Please enter a restaurant name below, if you have no idea about it, just click return')\n",
    "    name=input(\"restaurant name: \")\n",
    "\n",
    "    if name == '':\n",
    "        df = pd.read_csv(ab_path)\n",
    "        return False\n",
    "    elif name not in   \n",
    "    else:\n",
    "        df = pd.read_csv(ab_path)\n",
    "        return df.loc[df['restaurant_name'].isin([name])]\n",
    "\n",
    "ask_for_name('/Users/haodi_liu/Downloads/Sample Japanese Restaurant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
